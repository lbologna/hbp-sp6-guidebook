.. _validation_framework:

########################
HBP Validation Framework
########################

.. _vf-overview:

**************
Quick Overview
**************

We discuss here some of the terminology pertaining to the validation framework.

**Model**
   A Model or Model description consists of all the information pertaining to a
   model excluding details of the source code (i.e. implementation). The model
   would specify metadata describing the model type and its domain of utility.
   The source code is specified via the model instance (see below).

**Model Instance**
   This defines a particular version of a model by specifying the location of
   the source code for the model. A model may have multiple versions
   (model instances) which could vary, for example, in values of their
   biophysical parameters. Improvements and updates to a model would
   be considered as different versions (instances) of that particular model.

**Test**
   A Test or Test definition consists of all the information pertaining to a
   test excluding details of the source code (i.e. implementation). The test
   would specify metadata defining its domain of utility along with other info
   such as the type of data it handles and the type of score it generates.
   The source code is specified via the test instance (see below).

**Test Instance**
   This defines a particular version of a test by specifying the location of
   the source code for executing the test. A test may have multiple versions
   (test instances) which could vary, for example, in the way the simulation
   is setup or how the score is evaluated. Improvements in the test code would
   be considered as different versions (instances) of that particular test.

**sciunit**
   A Python package that handles testing of models.
   For more, see: https://github.com/scidash/sciunit

**Result**
   The outcome of testing a specific model instance with a specific test
   instance. The result would consist of a score, and possibly additionally
   output files generated by the test.

More detailed tutorials will be published soon.

.. _vf-general:

**************
General Info
**************

- From the above descriptions, it can be identified that *running a particular
  test for a model* under the validation framework is more accurately described as
  the *running of a specific test instance for a specific model instance*.

* When running a test, the test metadata and test instance info is typically
  retrieved from the validation framework. This involves authenticating your HBP
  login credentials.

- The model being tested can be registered on the *Model Catalog* beforehand,
  or asked to be registered automatically after the test is complete, just
  before registering the result on the validation framework.

* Registration of the model and its test results also require authenticating
  your HBP login credentials.

- It should be noted that an HBP account can be created even by non-HBP users.
  For more information, please visit: https://services.humanbrainproject.eu/oidc/account/request

* Collabs on the HBP Collaboratory can be either public or private. Public
  Collabs can be accessed by all registered users, whereas private Collabs
  require the user to be granted permission for access.

- The *Model Catalog* and the *Validation Framework* apps can be added to any
  Collab. A Collab may have multiple instances of these apps. The apps require
  to be *configured* by setting the provided filters appropriately before they
  can be used. These filters restrict the type of data displayed in that particular
  instance of the app.

* All tests are public, i.e. every test registered on the *Validation Framework*
  can be seen by all users.

- Models are created inside specific Collab instances of the *Model Catalog* app.
  The particular app inside which a model was created is termed its *host app*.
  Similarly, the Collab containing the *host app* is termed the *host Collab*.

* Models can be set as public/private. If public, the model and its associated
  results are available to all users. If private, it can only be seen by users who
  have access to the *host Collab*.

- No information can be deleted from the *Model Catalog* and *Validation Framework*
  apps. In future, an option to *hide* data would be implemented. This would offer
  users functionality similar to deleting, but with the data being retained in the
  database back-end.

* Models, model instances, tests and test instances can be edited as long as
  there are no results associated with them. Results can never be edited!


.. _vf-pyClient:

**************
Python Client
**************
The Validation Framework has a Python Client. This can be downloaded at:
  https://github.com/HumanBrainProject/hbp-validation-client

The documentation is available at:
  https://hbp-validation-client.readthedocs.io


.. _vf-restAPI:

*********
REST APIs
*********
The Validation Framework offers various REST APIs to access its various features and functionalities.
These are described in the documentation:  https://hbp-validation-framework-api.readthedocs.io


.. _vf-usecases:

*******************
Validation UseCases
*******************
We currently have the following usecases on the Collaboratory:

**1) Validation Framework Demo (Walkthrough)**
  This is designed as a walkthrough on using the validation framework. The specific example shown is for the Cerebellum.

**2) Hippocampus Single Cell - BluePyOpt Optimized Model Validation**
  This test shall take as input a BluePyOpt optimized output file. The validation tests run on the hoc template specified as "best_cell" in the meta.json file. There are a total of four different tests in this use case:

  - **Somatic Features Test:** *(for pyramidal cells and interneurons)*

    The Somatic Features Test can be used for both pyramidal cells and interneurons. It evaluates the model against various eFEL features under somatic current injection of varying amplitudes.

  - **Depolarization Block Test:** *(for pyramidal cells)*

    The Depolarization Block Test aims to determine whether the model enters depolarization block to prolonged, high intensity somatic current stimulus. It compares the current intensity to which the model fires the maximum number of action potentials, the current intensity before the model enters depolarization block (the two should be equal) and the equilibrium potential during depolarization block to the experimental data of Bianchi et al. 2012 (http://dx.doi.org/10.1007/s10827-012-0383-y).

  - **Back-Propagating AP Test:** *(for pyramidal cells)*

    The Back-Propagating AP Test evaluates the mode and efficacy of back-propagating action potentials on the apical trunk in locations of different distances from the soma. The amplitude of the first and last AP of around 15 Hz train is compared to experimental data from Golding et al. 2001 (https://doi.org/10.1152/jn.2001.86.6.2998).

  - **PSP Attenuation Test:** *(for pyramidal cells)*

    The PSP Attenuation Test evaluates how much the post synaptic potential (using EPSC stimulus) attenuates from the dendrite (different distances) to the soma. The soma/dendrite attenuation is compared to data from Magee & Cook 2000 (http://dx.doi.org/10.1038/78800).

The results are registered on the HBP Validation Framework app. If an instance of the Model Catalog and Validation Framework are not found in the current Collab, then these are created. Additionally, a test report is generated and this can be viewed within the Jupyter notebook, or downloaded.

**3) Basal Ganglia - BluePyOpt Optimized Model Validation - Multiple HOF**
  This test shall take as input a BluePyOpt optimized output file, containing a hall_of_fame.json file specifying a collection of parameter sets. The validation test would then evaluate the model for all (or specified) parameter sets against various eFEL features. The results are registered on the HBP Validation Framework app. If an instance of the Model Catalog and Validation Framework are not found in the current Collab, then these are created. Additionally, a test report is generated and this can be viewed within the Jupyter notebook, or downloaded.


**4) Generic - BluePyOpt Optimized Model Validation**
  This test shall take as input a BluePyOpt optimized output file. The validation test would then evaluate the model for all parameter sets against various eFEL features. It should be noted that the reference data used is that located within the model, so this test can be considered as a quantification of the goodness of fitting the model. The results are registered on the HBP Validation Framework app. If an instance of the Model Catalog and Validation Framework are not found in the current Collab, then these are created. Additionally, a test report is generated and this can be viewed within the Jupyter notebook, or downloaded.
